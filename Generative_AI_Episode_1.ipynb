{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Generative AI** It is Generating the new data.\n",
        "\n",
        "Generating new data can be in the form of Image Data,Video Data,Textual  Data.\n",
        "\n",
        "Tools like **ChatGPT,Perplexity,Gemini,Claude** are the examples of Generative AI which use the **LLM's(Large Language Models)**\n",
        "\n",
        "\n",
        "**Generative AI** tries to create a new content in the form of **Text ,Video,Images**\n",
        "\n",
        "\n",
        "**Real time applications that is used to create a text content**\n",
        "    **1.Chatbot used for Customer Services**\n",
        "    ** Websites that can create Presentatons (PPT's)**\n",
        "    **Code Generation Assist based tools-CoPiloit\n"
      ],
      "metadata": {
        "id": "H2AwqN0WC3PA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qbvhVIxKqq9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwv1DWjcClOz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLMs-Large Language Models**\n",
        "What are langauge models?\n",
        "Language Models are trained  to predict what comes next.\n",
        "\n",
        "Example - 1.Auto suggestion of the next word that is coming.\n",
        "\n",
        "          2.VSCode suggests what would be the next word.\n",
        "\n",
        "These language Models are called as **Large Language Models** because they are trained on huge amount of Data."
      ],
      "metadata": {
        "id": "5aF_vgEPFxJg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3wIiUxeClqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Generative AI concepts in Text Generation***\n",
        "\n",
        "**Internal working of Text Gneration - **\n",
        "\n",
        "Example : When we ask question to ChatGPT as  \"How are you?\"\n",
        "\n",
        "/*===================PREPROCESSING STEP============================*/\n",
        "\n",
        "**Step1-** The text broken down into individual words known as tokens\n",
        "      i)How\n",
        "      ii)are\n",
        "      iii)you\n",
        "      iv)?\n",
        "These are called as Tokens.\n",
        "\n",
        "The process of breaking the sentence into individual words iscalled as **\"Tokenisation\"**\n",
        "\n",
        "\n",
        "**Step-2** - Every token is converted into **Numeric Vectors**.This conversion is known as **Embedding**. Famous Embedding method is known as **Word2Vec**\n",
        "\n",
        "**Example to demonstrate Conversion of Tokens into numeric Vectors:-**\n",
        "king ,queen,man,woman ---> here we see that  \n",
        "**(king-queen) -->** there are synchronization.\n",
        "**(man-woman) -->** there are synchronization.\n",
        "\n",
        "Corresponding to every word vectors are created.\n",
        "\n",
        "These words can be related to the above 4 words\n",
        "\n",
        "rich ----(king & queen --rich can have vector value: 0.90)\n",
        "         (man & woman --rich can have vector value: 0.60)\n",
        "gender----(king and man --for male gender --0.90)\n",
        "          (queen & women --for female gender --0.10)\n",
        "dog,\n",
        "monkey\n",
        "human ----all 4 above are human so we write(1,1,1,1)\n",
        "plural---\n",
        "fruit ----above 4 words are not related to fruits,so we write(0,0,0,0)\n",
        "\n",
        "This process of converting Tokens to numeric Vectors is called as **Embeddings**\n",
        "\n",
        "Famous type of **Embedding** known as **Word2Vec**\n",
        "\n",
        "Two or more words which are related is given a higher value .\n",
        "Two re more words which are not related is given a  lower value.\n",
        "\n",
        "Example-\n",
        "\n",
        "    Cat-animal are related hence animal is given a value 0.91\n",
        "    Cat-fruit are not related hence fruit is given a value -0.51\n",
        "    puppy-fruit are not related hence fruit is given a value -0.91\n",
        "    houses-plural are related hence fruit is given a value 0.94\n",
        "\n",
        "Related words are given higher value that is close to 1\n",
        "Unrelated words are given lower value that is less and Negative.\n",
        "\n",
        "\n",
        "** Number of Features/Properties used is the **Number of Dimensions****\n",
        "\n",
        "Here 1024 values are used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AW9eakvFI9kd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider an example of Vector Operations(Numerical Operations)\n",
        "\n",
        "king - man + women\n",
        "\n",
        "King --> Vector values(0.5,0.7)\n",
        "man---> Vector values(0.5,0.2)\n",
        "women---> Vector values(0.3,0.4)\n",
        "\n",
        "\n",
        "Hence king - man +women ===>(0.5,0.7) - (0.5,0.2) + (0.3,0.4) =(0.3,0.9)==> This vector values matches with **Queen**.\n",
        "\n",
        "Hence we get king - man + women = Queen\n",
        "\n",
        "From this we conclude that the words that are very similar are in near range and the words that are very different are in farther range.\n",
        "\n",
        "\n",
        "Things will go wrong when a same word has different meaning.... Below are some of the examples:\n",
        "\n",
        "Apple===>(Company,Fruit)\n",
        "\n",
        "Bank====>(Finance Bank,River bank)\n",
        "\n",
        "\n",
        "Aftre Training the embeddings are fixed(as it is a **Static Embeddings**)\n",
        "Even though the context changes the Embeddings for the value wont change as its a Static Embedding.\n",
        "\n",
        "To handle this there came a use of Transformers which are based on the **Attention Mechanisim**\n",
        "\n",
        "**Attention Mechanisim** tries to see the context of the previous word and the upcomming word\n",
        "\n",
        "Transformers by Jay Allamar is famous Article based on Attention Mechanisim.\n",
        "\n",
        "Refer deeplearning.ai How Transformers work in LLM's\"\n",
        "\n",
        "**Transformer** is an Encoder-Decoder Architecture.\n",
        "\n",
        "**Encoder** ==> takes the Input\n",
        "\n",
        "**Decoder** ==> takes the Output.\n",
        "\n",
        "\n",
        "**Attention Mechanisim for  sentence**\n",
        "\n",
        "Example Statement : \"The Animal did'nt cross the street because it was too tired\"\n",
        "\n",
        "Step1:  The sentence is converted into multiple tokens as below:\n",
        "\"The\" \"Animal\" \"did'nt\" \"cross\" \"the\" \"street\" \"because\" \"it\" \"was\" \"too\" \"tire\n",
        "d\"\n",
        "\n",
        "\n",
        "Step2: Attention mechanisim is applied.Unique words are selected from the tokens.These group of unique words is called as Vocabulary size of theInput sentence.\n",
        "\n",
        "** Below code to see the tokens that are created for a text and the Vocablury Size----**\n",
        "\n",
        "\n",
        "import tiktoken\n",
        "encoder=tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "print(\"Vocalubary size:\",encoder.n_vocab)\n",
        "\n",
        "text=\"hello, how are you?\"\n",
        "tokens=encoder.encode(text)\n",
        "print(\"Tokens:\",tokens)\n",
        "\n",
        "\n",
        "decoded_text=encoder.decode(tokens)\n",
        "print(\"Decoded text:\",decoded_text)\n",
        "\n",
        "\"\"\"\n",
        "To find the Decoded text for an Individual token\n",
        "\n",
        "\"\"\"\n",
        "decoded_text=encoder.decode([24912])\n",
        "print(\"Decoded text:\",decoded_text)\n",
        "\n",
        "\n",
        "**Output-**\n",
        "\n",
        "Vocalubary size: 200019 =======>This means there 2 lakh 19 words are there.\n",
        "Below are the tokens created for the Input String \"Hello,how are you?\"\n",
        "Tokens: [24912, 11, 1495, 553, 481, 30]=======>\n",
        "Decoded text: hello, how are you?\n",
        "\n",
        "**Output-To find the Text for Individual Token**\n",
        "\n",
        "Decoded text: hello\n",
        "\n",
        "/*=================END OF PREPROCESSING============================*/\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "/*2.=======================HOW TEXT GENERATION HAPPENS======================*/\n",
        "Example : When a line is written as \" I hope you  are   doing  well\n",
        "                                                  ===== =====  ====\n",
        "          1. As seen in the above sentence when when you write \" I hope you\" it suggests \"are\"\n",
        "          2. When \"I hope you are\"  is written it suggests \"doing\"\n",
        "          3. When \" I hope you  are   doing\" is written it suggests \"well\"\n",
        "This is called as Language Modelling.\n",
        "\n",
        "How does Language Modelling takes place?\n",
        "\n",
        "Soln: Conditional Probabilty comes into Picture.\n",
        "\n",
        "We know : P(A|B) =P(A Intersection B)/ P(B)\n",
        "           \n",
        "           OR\n",
        "\n",
        "           P(A|B) = P(B|A) * P(A) / P(B)\n",
        "\n",
        "P(A|B) Indicates Probability of A given B\n",
        "\n",
        "Same conditional probability is applied when Text Generation happens as seen below:\n",
        "\n",
        "I===>Feature F1\n",
        "\n",
        "hope====> Feature F2\n",
        "\n",
        "you====> Feature F3\n",
        "\n",
        "are====> That it shows is predicted y**cap\n",
        "\n",
        "P(y**cap|F1,F2,F3) ===Probability of y**cap given F1,F2,F3\n",
        "\n",
        "Since Language models are trained with huge amount of data  ..It learns given the features what is next word that comes up.\n",
        "\n",
        "Whichever word has the \"BEST PROBABILITY \" that word is seen next.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "/*======================END OF TEXT GENERATION STEPS======================*/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**GPT ===> Generative Pretrained Transformers**\n",
        "\n",
        "\n",
        "**When initially Chat GPT came in 2022 ,they were not able to get the real Time data**.\n",
        "\n",
        "Hence came the \"Agentic AI\"\n",
        "\n",
        "\"Agentic AI\" are tools or Functions written internally.\n",
        "\n",
        "ChatGPT  is only the LLM's\n",
        "\n",
        "So along with LLM's  + Agentic AI(Tools) or Agents  were used to get the Real time data.\n",
        "\n",
        "Hence we are able to get the Real time data.\n",
        "\n",
        "Tools == Search_web== This goes and searches in the website and provides us the real data.\n",
        "\n",
        "hence along with LLM's ,Agnetic AI Tools or Agents ) are also required.\n",
        "\n",
        "\n",
        "** How was the sensitive handled ?\n",
        "\n",
        "RAG ====Retrival Agumented Generation\n",
        "came into picture to handle the sensitive data with LLM's\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jkJPChxb_70G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tI06w33oClt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7RwJDgnoClxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwEVdvt_Cl0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szrzhwNmCl39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcA5jMH0Cl7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-nJHiPSECl_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eATZgeF5CmCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ou86JV_YCmFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFLP3AV6CmIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1QQ5epTCmMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mz6exOvkCmPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PS26y864CmSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hlo25MUTCmWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDSxSrYwCmai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}